{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "x = [[0], [1], [2], [3]]\r\n",
    "y = [0, 0, 1, 1]\r\n",
    "\r\n",
    "# 实例化API\r\n",
    "estimator = KNeighborsClassifier(n_neighbors=2)\r\n",
    "# 使用fit方法进行训练\r\n",
    "estimator.fit(x, y)\r\n",
    "\r\n",
    "estimator.predict([[1]])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.datasets import load_iris\r\n",
    "# 获取鸢尾花数据集\r\n",
    "iris = load_iris()\r\n",
    "print(\"鸢尾花数据集的返回值：\\n\", iris)\r\n",
    "# 返回值是一个继承自字典的Bench\r\n",
    "print(\"鸢尾花的特征值:\\n\", iris[\"data\"])\r\n",
    "print(\"鸢尾花的目标值：\\n\", iris.target)\r\n",
    "print(\"鸢尾花特征的名字：\\n\", iris.feature_names)\r\n",
    "print(\"鸢尾花目标值的名字：\\n\", iris.target_names)\r\n",
    "print(\"鸢尾花的描述：\\n\", iris.DESCR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "鸢尾花数据集的返回值：\n",
      " {'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}\n",
      "鸢尾花的特征值:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "鸢尾花的目标值：\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "鸢尾花特征的名字：\n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "鸢尾花目标值的名字：\n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "鸢尾花的描述：\n",
      " .. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%matplotlib inline  \r\n",
    "# 内嵌绘图\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# 把数据转换成dataframe的格式\r\n",
    "iris_d = pd.DataFrame(iris['data'], columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width'])\r\n",
    "iris_d['Species'] = iris.target\r\n",
    "\r\n",
    "def plot_iris(iris, col1, col2):\r\n",
    "    sns.lmplot(x = col1, y = col2, data = iris, hue = \"Species\", fit_reg = False)\r\n",
    "    plt.xlabel(col1)\r\n",
    "    plt.ylabel(col2)\r\n",
    "    plt.title('鸢尾花种类分布图')\r\n",
    "    plt.show()\r\n",
    "plot_iris(iris_d, 'Petal_Width', 'Sepal_Length')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 403.125x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.datasets import load_iris\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "# 1、获取鸢尾花数据集\r\n",
    "iris = load_iris()\r\n",
    "# 对鸢尾花数据集进行分割\r\n",
    "# 训练集的特征值x_train 测试集的特征值x_test 训练集的目标值y_train 测试集的目标值y_test\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=22)\r\n",
    "print(\"x_train:\\n\", x_train.shape)\r\n",
    "# 随机数种子\r\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(iris.data, iris.target, random_state=6)\r\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(iris.data, iris.target, random_state=6)\r\n",
    "print(\"如果随机数种子不一致：\\n\", x_train == x_train1)\r\n",
    "print(\"如果随机数种子一致：\\n\", x_train1 == x_train2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train:\n",
      " (112, 4)\n",
      "如果随机数种子不一致：\n",
      " [[False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False  True]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False  True]\n",
      " [False False False  True]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [ True False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False  True]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True  True False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False  True]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [ True False False  True]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False  True]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False  True  True False]\n",
      " [False False False  True]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]]\n",
      "如果随机数种子一致：\n",
      " [[ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]\n",
      " [ True  True  True  True]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据的特征预处理"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "\r\n",
    "def minmax_demo():\r\n",
    "    \"\"\"\r\n",
    "    归一化演示\r\n",
    "    :return: None\r\n",
    "    \"\"\"\r\n",
    "    data = pd.read_csv(\"dating.txt\")\r\n",
    "    print(data)\r\n",
    "    # 1、实例化一个转换器类\r\n",
    "    transfer = MinMaxScaler(feature_range=(2, 3))\r\n",
    "    # 2、调用fit_transform\r\n",
    "    data = transfer.fit_transform(data[['milage','Liters','Consumtime']])\r\n",
    "    print(\"最小值最大值归一化处理的结果：\\n\", data)\r\n",
    "\r\n",
    "    return None\r\n",
    "minmax_demo()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   milage     Liters  Consumtime  target\n",
      "0   40920   8.326976    0.953952       3\n",
      "1   14488   7.153469    1.673904       2\n",
      "2   26052   1.441871    0.805124       1\n",
      "3   75136  13.147394    0.428964       1\n",
      "4   38344   1.669788    0.134296       1\n",
      "最小值最大值归一化处理的结果：\n",
      " [[2.43582641 2.58819286 2.53237967]\n",
      " [2.         2.48794044 3.        ]\n",
      " [2.19067405 2.         2.43571351]\n",
      " [3.         3.         2.19139157]\n",
      " [2.3933518  2.01947089 2.        ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "def stand_demo():\r\n",
    "    \"\"\"\r\n",
    "    标准化演示\r\n",
    "    :return: None\r\n",
    "    \"\"\"\r\n",
    "    data = pd.read_csv(\"dating.txt\")\r\n",
    "    print(data)\r\n",
    "    # 1、实例化一个转换器类\r\n",
    "    transfer = StandardScaler()\r\n",
    "    # 2、调用fit_transform\r\n",
    "    data = transfer.fit_transform(data[['milage','Liters','Consumtime']])\r\n",
    "    print(\"标准化的结果:\\n\", data)\r\n",
    "    print(\"每一列特征的平均值：\\n\", transfer.mean_)\r\n",
    "    print(\"每一列特征的方差：\\n\", transfer.var_)\r\n",
    "\r\n",
    "    return None\r\n",
    "stand_demo()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   milage     Liters  Consumtime  target\n",
      "0   40920   8.326976    0.953952       3\n",
      "1   14488   7.153469    1.673904       2\n",
      "2   26052   1.441871    0.805124       1\n",
      "3   75136  13.147394    0.428964       1\n",
      "4   38344   1.669788    0.134296       1\n",
      "标准化的结果:\n",
      " [[ 0.0947602   0.44990013  0.29573441]\n",
      " [-1.20166916  0.18312874  1.67200507]\n",
      " [-0.63448132 -1.11527928  0.01123265]\n",
      " [ 1.77297701  1.54571769 -0.70784025]\n",
      " [-0.03158673 -1.06346729 -1.27113187]]\n",
      "每一列特征的平均值：\n",
      " [3.8988000e+04 6.3478996e+00 7.9924800e-01]\n",
      "每一列特征的方差：\n",
      " [4.15683072e+08 1.93505309e+01 2.73652475e-01]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 以下是鸢尾花数据集的k临近算法全代码"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.datasets import load_iris\r\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "# 1.获取数据集\r\n",
    "iris = load_iris()\r\n",
    "\r\n",
    "# 2.数据基本处理\r\n",
    "# x_train,x_test,y_train,y_test为训练集特征值、测试集特征值、训练集目标值、测试集目标值\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=22)\r\n",
    "\r\n",
    "# 3、特征工程：标准化\r\n",
    "transfer = StandardScaler()\r\n",
    "x_train = transfer.fit_transform(x_train)\r\n",
    "x_test = transfer.transform(x_test)\r\n",
    "\r\n",
    "# 4、机器学习(模型训练)\r\n",
    "estimator = KNeighborsClassifier(n_neighbors=9)\r\n",
    "estimator.fit(x_train, y_train)\r\n",
    "# 5、模型评估\r\n",
    "# 方法1：比对真实值和预测值\r\n",
    "y_predict = estimator.predict(x_test)\r\n",
    "print(\"预测结果为:\\n\", y_predict)\r\n",
    "print(\"比对真实值和预测值：\\n\", y_predict == y_test)\r\n",
    "# 方法2：直接计算准确率\r\n",
    "score = estimator.score(x_test, y_test)\r\n",
    "print(\"准确率为：\\n\", score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "预测结果为:\n",
      " [0 2 1 2 1 1 1 1 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2]\n",
      "比对真实值和预测值：\n",
      " [ True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n",
      "准确率为：\n",
      " 0.9333333333333333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 鸢尾花案例增加K值调优"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 1、获取数据集\r\n",
    "iris = load_iris()\r\n",
    "# 2、数据基本处理 -- 划分数据集\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=22)\r\n",
    "# 3、特征工程：标准化\r\n",
    "# 实例化一个转换器类\r\n",
    "transfer = StandardScaler()\r\n",
    "# 调用fit_transform\r\n",
    "x_train = transfer.fit_transform(x_train)\r\n",
    "x_test = transfer.transform(x_test)\r\n",
    "# 4、KNN预估器流程\r\n",
    "#  4.1 实例化预估器类\r\n",
    "estimator = KNeighborsClassifier()\r\n",
    "\r\n",
    "# 4.2 模型选择与调优——网格搜索和交叉验证\r\n",
    "# 准备要调的超参数\r\n",
    "param_dict = {\"n_neighbors\": [1, 3, 5]}\r\n",
    "estimator = GridSearchCV(estimator, param_grid=param_dict, cv=3)\r\n",
    "# 4.3 fit数据进行训练\r\n",
    "estimator.fit(x_train, y_train)\r\n",
    "# 5、评估模型效果\r\n",
    "# 方法a：比对预测结果和真实值\r\n",
    "y_predict = estimator.predict(x_test)\r\n",
    "print(\"比对预测结果和真实值：\\n\", y_predict == y_test)\r\n",
    "# 方法b：直接计算准确率\r\n",
    "score = estimator.score(x_test, y_test)\r\n",
    "print(\"直接计算准确率：\\n\", score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "比对预测结果和真实值：\n",
      " [ True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "直接计算准确率：\n",
      " 0.9473684210526315\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(\"在交叉验证中验证的最好结果：\\n\", estimator.best_score_)\r\n",
    "print(\"最好的参数模型：\\n\", estimator.best_estimator_)\r\n",
    "print(\"每次交叉验证后的准确率结果：\\n\", estimator.cv_results_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "在交叉验证中验证的最好结果：\n",
      " 0.9732100521574205\n",
      "最好的参数模型：\n",
      " KNeighborsClassifier()\n",
      "每次交叉验证后的准确率结果：\n",
      " {'mean_fit_time': array([0.00067019, 0.00100851, 0.00033347]), 'std_fit_time': array([4.73903573e-04, 1.67877834e-05, 4.71595137e-04]), 'mean_score_time': array([0.00265725, 0.00232371, 0.00234024]), 'std_score_time': array([0.0009497 , 0.00048226, 0.00045881]), 'param_n_neighbors': masked_array(data=[1, 3, 5],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}], 'split0_test_score': array([0.97368421, 0.97368421, 0.97368421]), 'split1_test_score': array([0.97297297, 0.97297297, 0.97297297]), 'split2_test_score': array([0.94594595, 0.89189189, 0.97297297]), 'mean_test_score': array([0.96420104, 0.94618303, 0.97321005]), 'std_test_score': array([0.01291157, 0.03839073, 0.00033528]), 'rank_test_score': array([2, 3, 1])}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 案例2：预测facebook签到位置"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 1、获取数据集\r\n",
    "facebook = pd.read_csv(\"./fb/train.csv\")\r\n",
    "\r\n",
    "# 2.基本数据处理\r\n",
    "# 2.1 缩小数据范围\r\n",
    "facebook_data = facebook.query(\"x>2.0 & x<2.5 & y>2.0 & y<2.5\")\r\n",
    "# 2.2 选择时间特征\r\n",
    "time = pd.to_datetime(facebook_data[\"time\"], unit=\"s\")\r\n",
    "time = pd.DatetimeIndex(time)\r\n",
    "facebook_data[\"day\"] = time.day\r\n",
    "facebook_data[\"hour\"] = time.hour\r\n",
    "facebook_data[\"weekday\"] = time.weekday\r\n",
    "# 2.3 去掉签到较少的地方\r\n",
    "place_count = facebook_data.groupby(\"place_id\").count()\r\n",
    "place_count = place_count[place_count[\"row_id\"]>3]\r\n",
    "facebook_data = facebook_data[facebook_data[\"place_id\"].isin(place_count.index)]\r\n",
    "# 2.4 确定特征值和目标值\r\n",
    "x = facebook_data[[\"x\", \"y\", \"accuracy\", \"day\", \"hour\", \"weekday\"]]\r\n",
    "y = facebook_data[\"place_id\"]\r\n",
    "# 2.5 分割数据集\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=22)\r\n",
    "\r\n",
    "# 3.特征工程--特征预处理(标准化)\r\n",
    "# 3.1 实例化一个转换器\r\n",
    "transfer = StandardScaler()\r\n",
    "# 3.2 调用fit_transform\r\n",
    "x_train = transfer.fit_transform(x_train)\r\n",
    "x_test = transfer.fit_transform(x_test)\r\n",
    "\r\n",
    "# 4.机器学习--knn+cv\r\n",
    "# 4.1 实例化一个估计器\r\n",
    "estimator = KNeighborsClassifier()\r\n",
    "# 4.2 调用gridsearchCV\r\n",
    "param_grid = {\"n_neighbors\": [1, 3, 5, 7, 9]}\r\n",
    "estimator = GridSearchCV(estimator, param_grid=param_grid, cv=5)\r\n",
    "# 4.3 模型训练\r\n",
    "estimator.fit(x_train, y_train)\r\n",
    "\r\n",
    "# 5.模型评估\r\n",
    "# 5.1 基本评估方式\r\n",
    "score = estimator.score(x_test, y_test)\r\n",
    "print(\"最后预测的准确率为:\\n\", score)\r\n",
    "\r\n",
    "y_predict = estimator.predict(x_test)\r\n",
    "print(\"最后的预测值为:\\n\", y_predict)\r\n",
    "print(\"预测值和真实值的对比情况:\\n\", y_predict == y_test)\r\n",
    "\r\n",
    "# 5.2 使用交叉验证后的评估方式\r\n",
    "print(\"在交叉验证中验证的最好结果:\\n\", estimator.best_score_)\r\n",
    "print(\"最好的参数模型:\\n\", estimator.best_estimator_)\r\n",
    "print(\"每次交叉验证后的验证集准确率结果和训练集准确率结果:\\n\",estimator.cv_results_)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Memphis\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Memphis\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Memphis\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Memphis\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "最后预测的准确率为:\n",
      " 0.36567336567336567\n",
      "最后的预测值为:\n",
      " [9983648790 6329243787 9674001925 ... 2990018952 4830766946 7065571836]\n",
      "预测值和真实值的对比情况:\n",
      " 24703810     True\n",
      "19445902    False\n",
      "18490063     True\n",
      "7762709     False\n",
      "6505956     False\n",
      "            ...  \n",
      "27632888    False\n",
      "23367671    False\n",
      "6692268      True\n",
      "25834435    False\n",
      "13319005    False\n",
      "Name: place_id, Length: 17316, dtype: bool\n",
      "在交叉验证中验证的最好结果:\n",
      " 0.3546044971864908\n",
      "最好的参数模型:\n",
      " KNeighborsClassifier(n_neighbors=1)\n",
      "每次交叉验证后的验证集准确率结果和训练集准确率结果:\n",
      " {'mean_fit_time': array([0.08860288, 0.09177833, 0.08719702, 0.09020133, 0.0958075 ]), 'std_fit_time': array([0.00134271, 0.00668601, 0.00115361, 0.00213368, 0.01565806]), 'mean_score_time': array([0.4174005 , 0.46400537, 0.49140906, 0.5369988 , 0.60299673]), 'std_score_time': array([0.01769253, 0.00804902, 0.00545521, 0.02057379, 0.05240881]), 'param_n_neighbors': masked_array(data=[1, 3, 5, 7, 9],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}, {'n_neighbors': 7}, {'n_neighbors': 9}], 'split0_test_score': array([0.35948027, 0.34311838, 0.35235804, 0.35303176, 0.34927815]), 'split1_test_score': array([0.35466795, 0.34369586, 0.35563041, 0.35370549, 0.34821944]), 'split2_test_score': array([0.35524543, 0.34119346, 0.3506256 , 0.35129933, 0.34860443]), 'split3_test_score': array([0.3514294 , 0.34141881, 0.35681971, 0.35537588, 0.35075561]), 'split4_test_score': array([0.35219944, 0.34161132, 0.35152565, 0.34757917, 0.34132255]), 'mean_test_score': array([0.3546045 , 0.34220757, 0.35339188, 0.35219832, 0.34763604]), 'std_test_score': array([0.00283032, 0.00100506, 0.00240687, 0.00265359, 0.00327312]), 'rank_test_score': array([1, 5, 2, 3, 4])}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('myenv': conda)"
  },
  "interpreter": {
   "hash": "a0c4eabb6bbdafe74e9343f06eb0ddaead977bb9e3726d982ccb327fc4478aed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}